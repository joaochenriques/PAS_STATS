{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNFWRyN6UdnQmaJx3y2ajCP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaochenriques/PAS_STATS/blob/main/PAS_STATS_V02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UYVFDSKmZ4z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as mpl\n",
        "import sys, pathlib\n",
        "import itertools\n",
        "from scipy import optimize\n",
        "from sortedcontainers import SortedDict\n",
        "\n",
        "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,AutoMinorLocator)\n",
        "\n",
        "import pathlib, subprocess\n",
        "\n",
        "def cmdcall( cmd ):\n",
        "    output = subprocess.getoutput( cmd )\n",
        "    print(output)\n",
        "\n",
        "if not pathlib.Path(\"mpl_utils.py\").exists():\n",
        "  cmdcall( 'curl -O https://raw.githubusercontent.com/joaochenriques/ipynb_libs/main/mpl_utils.py' )\n",
        "\n",
        "import mpl_utils as mut\n",
        "mut.config_plots()\n",
        "\n",
        "markers = ( 'o', '^', 's', 'v', 'H', 'X', 'P' )\n",
        "\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dataclassy\n",
        "from dataclassy import dataclass"
      ],
      "metadata": {
        "id": "-RikPqO55cJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install iso3166\n",
        "from iso3166 import countries\n",
        "\n",
        "country_lst = []\n",
        "for c in countries:\n",
        "    country_lst.append( c.name )"
      ],
      "metadata": {
        "id": "llW3nHzIsEiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scopus advanced search query\n",
        "\n",
        "```\n",
        "TITLE-ABS-KEY-AUTH(WAVE-ENERGY) AND PUBYEAR AFT 2003 AND DOCTYPE(ar OR re) AND\n",
        "(\n",
        "    SRCTITLE(applied-energy) OR\n",
        "    SRCTITLE(applied-ocean-research) OR\n",
        "    SRCTITLE(energy) OR\n",
        "    SRCTITLE(energy-conversion-and-management ) OR\n",
        "    SRCTITLE(energies) OR\n",
        "    SRCTITLE(ieee-transactions-on-sustainable-energy) OR\n",
        "    SRCTITLE(iet-renewable-power-generation) OR\n",
        "    SRCTITLE(international-journal-of-marine-energy ) OR\n",
        "    SRCTITLE(international-journal-of-offshore-and-polar-engineering ) OR\n",
        "    SRCTITLE(journal-of-offshore-mechanics-and-arctic-engineering) OR\n",
        "    SRCTITLE(Journal-of-Ocean-Engineering-and-Marine-Energy) OR\n",
        "    SRCTITLE(ocean-engineering) OR\n",
        "    SRCTITLE(marine-structures) OR\n",
        "    SRCTITLE(renewable-energy) OR\n",
        "    SRCTITLE(renewable-sustainable-energy-reviews) \n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "xpVdtPzypxbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'scopus_20230608D.csv'\n",
        "if 'google.colab' in sys.modules and not pathlib.Path( f\"{filename}\").exists():\n",
        "    cmdcall( f'curl -O https://raw.githubusercontent.com/joaochenriques/PAS_STATS/main/{filename}' )"
      ],
      "metadata": {
        "id": "nB9IJvu6mlv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv( filename )\n",
        "df.keys()"
      ],
      "metadata": {
        "id": "bZg8TPI2m2uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "affiliations_lst = df['Affiliations']\n",
        "stage_lst = df['Publication Stage'] \n",
        "\n",
        "replacements_dic = {   \n",
        "    'Ireland (formerly at the University of Plymouth)': 'Ireland',\n",
        "    'Univ. Paris6': 'France',\n",
        "    'Chinese Academy of Sciences': 'China',\n",
        "    'Instituto Superior Tx000E9': 'Portugal'\n",
        "}"
      ],
      "metadata": {
        "id": "NqQTY6x5t5KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Countries ordered by first author"
      ],
      "metadata": {
        "id": "fERqrty1SpzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "countries_1st_dic = {}\n",
        "total_valid_papers = 0\n",
        "\n",
        "for n, ( affiliations, stage ) in enumerate( zip( affiliations_lst, stage_lst ) ):\n",
        "    if stage == 'Final' and affiliations == affiliations: # detect NANs\n",
        "        total_valid_papers += 1\n",
        "\n",
        "        affiliations_unique = [] \n",
        "        \n",
        "        for i in affiliations.split( ';' ): \n",
        "            if i not in affiliations_unique: \n",
        "                affiliations_unique.append(i) \n",
        "            # else:\n",
        "            #     print( 'Duplicate:', n )\n",
        "            #     print( affiliations )\n",
        "\n",
        "        for institution in affiliations_unique:\n",
        "            country = institution.rsplit( ',', 1 )[-1].strip()\n",
        "\n",
        "            if country in replacements_dic:\n",
        "                country = replacements_dic[country]\n",
        "\n",
        "            if not country in countries_1st_dic:\n",
        "                countries_1st_dic[country] = 1\n",
        "            else:\n",
        "                countries_1st_dic[country] += 1\n",
        "    \n",
        "sorted_country_1st_rank = { k: v for k, v in sorted( countries_1st_dic.items(), key=lambda item: item[1], reverse=True ) }\n",
        "\n",
        "for ( name, num ) in sorted_country_1st_rank.items():\n",
        "    if num > 50:\n",
        "        print( name, num )"
      ],
      "metadata": {
        "id": "sk83Jym2un08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Countries ordered by percentage of the authors's country"
      ],
      "metadata": {
        "id": "EK5Xo34HS62d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "countries_frac_dic = {}\n",
        "total_valid_papers = 0\n",
        "\n",
        "for n, ( affiliations, stage ) in enumerate( zip( affiliations_lst, stage_lst ) ):\n",
        "    if stage == 'Final' and affiliations == affiliations: # detect NANs\n",
        "        total_valid_papers += 1\n",
        "\n",
        "        institutions_lst = affiliations.split( ';' )\n",
        "        frac = 1.0 / len(institutions_lst)\n",
        "\n",
        "        for institution in institutions_lst:\n",
        "            country = institution.rsplit( ',', 1 )[-1].strip()\n",
        "\n",
        "            if country in replacements_dic:\n",
        "                country = replacements_dic[country]\n",
        "\n",
        "            if not country in countries_frac_dic:\n",
        "                countries_frac_dic[country] = frac\n",
        "            else:\n",
        "                countries_frac_dic[country] += frac\n",
        "\n",
        "sorted_country_frac_rank = { k: v for k, v in sorted( countries_frac_dic.items(), key=lambda item: item[1], reverse=True ) }\n",
        "\n",
        "print( \"Number of valid papers: \", int(total_valid_papers) )\n",
        "\n",
        "for n, ( name, num ) in enumerate( sorted_country_frac_rank.items() ):\n",
        "    if n >= 10:\n",
        "        break\n",
        "    print( n+1, name, int(num) )"
      ],
      "metadata": {
        "id": "87OqHiyQTEdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Number of papers per author, citations, and highest cited paper"
      ],
      "metadata": {
        "id": "WnsbSaBQTHGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "authors_lst = df['Authors']\n",
        "authors_ID_lst = df['Author(s) ID'] \n",
        "citations_lst = df['Cited by']\n",
        "\n",
        "@dataclass\n",
        "class data:\n",
        "    name: str = None\n",
        "    num_papers: int = 0\n",
        "    citations: int = 0\n",
        "    highest_cited: int = 0"
      ],
      "metadata": {
        "id": "c98Yyl9e0DjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papers_dic = {}\n",
        "\n",
        "for n, ( authors, authors_ID, citations, stage ) in enumerate( zip( authors_lst, authors_ID_lst, citations_lst, stage_lst ) ):\n",
        "    if stage == 'Final' and authors == authors and authors_ID == authors_ID: # check NANs\n",
        "        for ( author, ID ) in zip( authors.split(';'), str( authors_ID ).split(';') ):\n",
        "            author = author.strip()\n",
        "            ID = ID.strip()\n",
        "\n",
        "            if ID in papers_dic:\n",
        "                papers_dic[ID].num_papers += 1\n",
        "                papers_dic[ID].citations += int(citations)\n",
        "                papers_dic[ID].highest_cited = max( papers_dic[ID].highest_cited, int(citations) )\n",
        "            else:\n",
        "                papers_dic[ID] = data( author, 1, int(citations), int(citations) )"
      ],
      "metadata": {
        "id": "ja-ZA6lGx4YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_papers_dic = { k: v for k, v in sorted( papers_dic.items(), key=lambda item: item[1].num_papers, reverse=True ) }\n",
        "for n, author_data in enumerate( sorted_papers_dic.values() ):\n",
        "    if author_data.num_papers >= 25:\n",
        "        print( n+1, author_data.name, author_data.num_papers )"
      ],
      "metadata": {
        "id": "-jjYjDaa49VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_citations_dic = { k: v for k, v in sorted( papers_dic.items(), key=lambda item: item[1].citations, reverse=True ) }\n",
        "for n, author_data in enumerate( sorted_citations_dic.values() ):\n",
        "    if n >= 20:\n",
        "        break\n",
        "    print( n+1, author_data.name, author_data.citations )"
      ],
      "metadata": {
        "id": "SG8KjEDp6A76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_highest_cited_dic = { k: v for k, v in sorted( papers_dic.items(), key=lambda item: item[1].highest_cited, reverse=True ) }\n",
        "for n, author_data in enumerate( sorted_highest_cited_dic.values() ):\n",
        "    if n >= 20:\n",
        "        break\n",
        "    print( n+1, author_data.name, author_data.highest_cited )"
      ],
      "metadata": {
        "id": "yz-8yOBPXxjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F44gD-KFYQNk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}